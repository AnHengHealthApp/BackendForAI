"""
åˆå§‹åŒ– Chroma Vector Database
è®€å– medicine_completion.jsonl ä¸¦å»ºç«‹å‘é‡ç´¢å¼•
"""
import json
import os
from pathlib import Path
from dotenv import load_dotenv
import chromadb
from chromadb.config import Settings
from openai import OpenAI

load_dotenv()

BASE_DIR = Path(__file__).parent.parent
DATA_FILE = BASE_DIR / "data" / "medicine_completion.jsonl"
CHROMA_DB_PATH = BASE_DIR / "chroma_db"

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
EMBEDDING_MODEL = "text-embedding-3-small"

def get_embeddings_batch(texts: list[str], client: OpenAI) -> list[list[float]]:
    response = client.embeddings.create(
        input=texts,
        model=EMBEDDING_MODEL
    )

    return [data.embedding for data in response.data]

def initialize_chroma_db():
    print("ğŸš€ é–‹å§‹åˆå§‹åŒ– Chroma Vector Database...")

    if not DATA_FILE.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ: {DATA_FILE}\n"
            f"è«‹ç¢ºèª medicine_completion.jsonl å·²æ”¾å…¥ data/ è³‡æ–™å¤¾"
        )

    client = OpenAI(api_key=OPENAI_API_KEY)

    chroma_client = chromadb.PersistentClient(
        path=str(CHROMA_DB_PATH),
        settings=Settings(
            anonymized_telemetry=False,
            allow_reset=True
        )
    )

    try:
        chroma_client.delete_collection(name="medicine_db")
        print("ğŸ—‘ï¸  å·²åˆªé™¤èˆŠçš„ collection")
    except:
        pass

    collection = chroma_client.create_collection(
        name="medicine_db",
        metadata={"description": "é†«è—¥è³‡æ–™å‘é‡è³‡æ–™åº«"}
    )

    print(f"ğŸ“– è®€å–è³‡æ–™æª”æ¡ˆ: {DATA_FILE}")
    medicines = []
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                medicines.append(json.loads(line))

    print(f"âœ… å…±è¼‰å…¥ {len(medicines)} ç­†é†«è—¥è³‡æ–™")

    batch_size = 100 # 500~1000
    total_batches = (len(medicines) + batch_size - 1) // batch_size

    for i in range(0, len(medicines), batch_size):
        batch = medicines[i:i + batch_size]
        batch_num = i // batch_size + 1

        print(f"ğŸ”„ è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} ç­†è³‡æ–™)...")

        ids = []
        documents = []
        metadatas = []
        texts_for_embedding = []

        for idx, medicine in enumerate(batch):
            medicine_name = medicine.get("medicine", "")
            completion = medicine.get("completion", "")

            combined_text = f"{medicine_name}: {completion}"

            ids.append(f"med_{i + idx}")
            documents.append(combined_text)
            metadatas.append({
                "medicine": medicine_name,
                "completion": completion
            })
            texts_for_embedding.append(combined_text)

        embeddings = get_embeddings_batch(texts_for_embedding, client)

        collection.add(
            ids=ids,
            documents=documents,
            metadatas=metadatas,
            embeddings=embeddings
        )

    print(f"âœ¨ æˆåŠŸå»ºç«‹å‘é‡è³‡æ–™åº«ï¼")
    print(f"ğŸ“Š ç¸½è¨ˆå„²å­˜: {len(medicines)} ç­†è³‡æ–™")
    print(f"ğŸ’¾ è³‡æ–™åº«ä½ç½®: {CHROMA_DB_PATH}")

    count = collection.count()
    print(f"âœ… é©—è­‰å®Œæˆï¼Œè³‡æ–™åº«å…§æœ‰ {count} ç­†è¨˜éŒ„")

    return collection

if __name__ == "__main__":
    try:
        initialize_chroma_db()
        print("\nğŸ‰ åˆå§‹åŒ–å®Œæˆï¼ç¾åœ¨å¯ä»¥å•Ÿå‹• API æœå‹™äº†ã€‚")
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        raise